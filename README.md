# ğŸ§  LangChain Agent API with MongoDB & Gemini

A FastAPI-based backend for a **web research assistant** powered by **LangChain**, **Google Gemini**, and **Tavily Search**, with **MongoDB**-based session persistence.

> ğŸš€ Built for applications that require contextual, session-aware, and tool-augmented AI conversations.

---

## ğŸ“¦ Features

* âœ… Conversational memory stored in MongoDB
* ğŸ” Real-time web search using Tavily API
* ğŸ¤– Gemini 2.5-powered agent via LangChain
* ğŸŒ CORS-enabled FastAPI endpoints
* ğŸ§  Context injection using system prompts
* ğŸ›  Tool calling agent execution via LangChain
* ğŸ§ª Health check and session management

---

## ğŸ”§ Environment Setup

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

Or manually install:

```bash
pip install fastapi uvicorn python-dotenv \
    langchain langchain-community \
    langchain-google-genai langchain-mongodb \
    tavily-python
```

### 2. Set Environment Variables

Create a `.env` file:

```env
TAVILY_API_KEY=your_tavily_api_key
GOOGLE_API_KEY=your_google_api_key
MONGODB_URI=mongodb://localhost:27017
DB_NAME=chat_db
COLLECTION_NAME=chat_histories
```

---

## â–¶ï¸ Running the Server

```bash
uvicorn main:app --host 0.0.0.0 --port 5000 --reload
```

---

## ğŸ§ª API Endpoints

### `POST /set_context`

Set initial context for a session. Creates a new session if `session_id` is not provided.

**Request:**

```json
{
  "context": {
    "user": "Ali",
    "topic": "machine learning"
  },
  "session_id": "optional-session-id"
}
```

**Response:**

```json
{
  "session_id": "generated-or-supplied-id",
  "status": "context_set"
}
```

---

### `POST /chat`

Send a message to the agent and get a response based on the current session.

**Request:**

```json
{
  "message": "What is LangChain?",
  "session_id": "your-session-id"
}
```

**Response:**

```json
{
  "response": "LangChain is a framework for...",
  "session_id": "your-session-id",
  "history": [
    { "role": "user", "content": "What is LangChain?" },
    { "role": "assistant", "content": "LangChain is a framework for..." }
  ]
}
```

---

### `GET /history/{session_id}`

Fetch the full message history for a given session.

**Response:**

```json
{
  "session_id": "abc-123",
  "history": [
    { "role": "system", "content": "Additional context..." },
    { "role": "user", "content": "..." },
    { "role": "assistant", "content": "..." }
  ]
}
```

---

### `GET /health`

Performs a health check including database connection.

**Response:**

```json
{
  "status": "healthy",
  "database": "connected"
}
```

---

## ğŸ“š Project Structure

```
â”œâ”€â”€ main.py              # Main FastAPI app
â”œâ”€â”€ .env                 # API keys and configuration
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # You're here!
```

---

## ğŸ›¡ï¸ Tech Stack

* **FastAPI** â€” Python web framework
* **LangChain** â€” LLM orchestration
* **Gemini 2.5** â€” Google Generative AI model
* **Tavily API** â€” Web search results
* **MongoDB** â€” Message history storage
* **Uvicorn** â€” ASGI server

---

## ğŸ§  Agent Logic

* Uses `ChatGoogleGenerativeAI` from LangChain
* Prompt template includes system message + message history + scratchpad
* Augmented with `TavilySearchResults` tool for live search
* Stateful using `MongoDBChatMessageHistory`

---

## ğŸ“Œ TODO / Improvements

* [ ] Add user authentication
* [ ] Rate limiting and session expiry
* [ ] Frontend UI (React or Next.js)
* [ ] Advanced context injection (memory summarization)

